# Common
random_seed: 42

learning_rate: 0.001 # Input model's learning rate

# clustering/HPO Options
hyperparams:
- [1.000e-5, 128]
- [3.162e-4, 32]
- [1.000e-2, 8]

model_type: 'Pytorch' # This value should be maintained
model:
  _target_: models.DiabetesClassifier # Input your custom model
  input_size: 52  
  output_size: 2 # Input your model's output size (only classification)

dataset:
    name: 'diabetes_dataset' # Input your data name
    validation_split: 0.1 # Ratio of dividing train data by validation

# client
task_id: 'diabetesdatasetrr' # Input your Task Name that you register in FedOps Website

wandb: 
  use: false # Whether to use wandb
  key: 'your wandb api key' # Input your wandb api key
  account: 'your wandb account' # Input your wandb account
  project: '${dataset.name}_${task_id}'

# server
num_epochs: 1 # number of local epochs
batch_size: 32
num_rounds: 1 # Number of rounds to perform
clients_per_round: 1 # Number of clients participating in the round

server:
  strategy:
    _target_: fedops.server.strategy_cluster_optuna.ClusterOptunaFedAvg # aggregation algorithm
    fraction_fit: 0.00001
    fraction_evaluate: 0.000001
    min_fit_clients: ${clients_per_round}
    min_available_clients: ${clients_per_round}
    min_evaluate_clients: ${clients_per_round}

    # clustering/HPO Options
    warmup_rounds: 1        # Number of warmup rounds before clustering
    recluster_every: 1      # Re-cluster frequency (in rounds)
    eps: 0.2                # DBSCAN epsilon parameter
    min_samples: 2          # DBSCAN min_samples parameter
    objective: "maximize_f1"        # Other options: "maximize_acc" / "minimize_loss"
    search_lr_log: [-5.0, -2.0]     # Search space for log10(lr), e.g. 1e-5 to 1e-2
    search_bs_exp: [3, 7]           # Search space for batch size as 2^exp (8~128)
    search_local_epochs: [1, 3]     # Range of local epochs
